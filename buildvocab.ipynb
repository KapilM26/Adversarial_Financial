{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import typer\nimport advsber\nfrom allennlp.data import Vocabulary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\n    This function reads the training and validation data, combines them, \n    creates a vocabulary from the combined data, and saves it to disk.\n\"\"\"\n\n# Function to process dataset, create vocabulary, and save it to files\ndef create_and_save_vocab(dataset_name: str):\n    \n    # Initialize the reader for the transactions dataset\n    reader = advsber.TransactionsDatasetReader(f'presets/{dataset_name}/discretizers/100_quantile')\n    \n    # Read the train and validation data\n    train_data = reader.read(f'../data/{dataset_name}/lm/train.jsonl')\n    valid_data = reader.read(f'../data/{dataset_name}/lm/valid.jsonl')\n    \n    # Combine the train and validation data\n    combined_data = train_data + valid_data\n    \n    # Define special tokens to add to the vocabulary\n    special_tokens = {\n        \"transactions\": [\"@@MASK@@\", \"<START>\", \"<END>\"],\n        \"amounts\": [\"<START>\", \"<END>\"]\n    }\n    \n    # Create the vocabulary from the combined data and the special tokens\n    vocab = Vocabulary.from_instances(combined_data, tokens_to_add=special_tokens)\n    \n    # Save the vocabulary to disk\n    vocab_file_path = f'./presets/{dataset_name}/vocabs/100_quantile'\n    vocab.save_to_files(vocab_file_path)\n    \n    print(f\"Vocabulary for {dataset_name} saved to {vocab_file_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Use the below cell to execute notebook**","metadata":{}},{"cell_type":"code","source":"# Run the function for a dataset\ndataset_name = \"rosbank\"  # Replace with the dataset name\ncreate_and_save_vocab(dataset_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}